\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Big Data - Blatt 02}
\author{Matthias Werft, André Wetzel, Marius Köppel}
\date{\today}

\usepackage{natbib}
\usepackage{graphicx}
\usepackage{subfigure}

\usepackage{listings}
\usepackage{color}

%from https://stackoverflow.com/questions/3175105/writing-code-in-latex-document
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
	language=Java,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}


\begin{document}

\maketitle

\section{Nr 1}

\subsection{Teilaufgabe a)}

\paragraph{Mapper}
\begin{lstlisting}
map(key, value):
	//der letzte Eintrag des Key-Tupels ist der Knoten,
	//an dem die Kante eingeht
	emit(key.last, value)
\end{lstlisting}

\paragraph{Reducer}
\begin{lstlisting}
reduce(key, values):
	sum = 0
	//Man gruppiert nur nach den Knoten, in die die Kanten eingehen
	//und summiert einfach die Gewichte der eingehenden Kanten.
	for each v in values:
		sum += v
	emit(key, sum)
\end{lstlisting}

\subsection{Teilaufgabe b)}

\paragraph{Mapper}
\begin{lstlisting}
map(key, value):
	//ein Kante (hier der key) kann in einem 2-Pfad entweder die erste
	emit(key.last, (key, value))
	//oder die zweite Kante sein
	emit(key.first, (key, value))
	//Der neue key (erstes Argument in emit) ist der mittlere Knoten
	//im 2-Pfad, nach dem in shuffle gruppiert werden soll.
	//Der value ist das Eingabe-Key-Value-Paar.
\end{lstlisting}

\newpage

\paragraph{Reducer}
\begin{lstlisting}
reduce(key, values):
	//Liste fuer die ersten Kanten in den 2-Pfaden
	left = []
	//Liste fuer die zweiten Kanten in den 2-Pfaden
	right = []
	for each v in values:
		//falls der key in der Kante hinten ist, ist es eine erste Kante
		if v.first.last == key:
			left.add(v)
		//falls der key in der Kante vorne ist, ist es eine zweite Kante
		else:        //if v.first.first == key
			right.add(v)
	//versuche, 2-Pfade zu konstruieren und als Key-Value-Paar mit
	//einem Tripel und den addierten Kantengewichten zu emittieren
	for each u in left:
		for each v in right:
			emit((u.first.first, key, v.first.last), u.last + v.last)
\end{lstlisting}


\section{Nr 2}

\subsection{Teilaufgabe a)}
Wenn die Map-Operation parallelisiert wird, werden die Eingabedaten in mehrere Teile (Splits) aufgeteilt.
Diese Splits werden im Rahmen des InputFormat in Datensätze (records) unterteilt und jeder Datensatz wird vom Mapper verarbeitet.

\subsection{Teilaufgabe b)}

\paragraph{InputFormat:}
Wählt Dateien oder andere Objekte aus, die für die Eingabe verwendet werden sollen und definiert, wie diese in Hadoop aufgeteilt und gelesen werden.

\paragraph{InputSplit:}
InputSplit repräsentiert die Daten, die von einem einzelnen Mapper verarbeitet werden. Die InputSplit-Länge wird in Bytes gemessen und jeder InputSplit verfügt über Speicherorte. MapReduce verwendet diese, um Map-Aufgaben so nah wie möglich an die Split-Daten zu platzieren. Map-Aufgaben werden in der Reihenfolge der Größe der Splits verarbeitet, so dass die größte zuerst verarbeitet wird. Außerdem ist zu erwähnen, dass Inputsplit nicht die Eingabedaten enthält, sondern nur eine Referenz auf die Daten darstellt.

\paragraph{Record Reader:}
Der Record Reader kommuniziert mit dem InputSplit in Hadoop MapReduce und konvertiert die Daten in Key/Value - Paare, die zum Lesen durch den Mapper geeignet sind. Standardmäßig verwendet es dafür TextinputFormat. Außerdem wird jeder in der Datei vorhandenen Zeile wird eine eindeutige Nummer zugeordnet.

\subsection{Teilaufgabe c)}
Das standard Inputformat ist TextInputFormat. Man erhält ein Key/Value - Paar als <longwriteable/text> in der Map Methode.

\subsection{Teilaufgabe d)}
Abgesehen von der Map Methode gibt es drei zusätzliche Methoden, die falls benötigt überschrieben werden können.

\paragraph{Setup:}
Die Setup Methode wird einmal aufgerufen, bevor Key/Value – Paare der Map Methode übergeben werden. Die Standardimplementierung macht nichts.

\paragraph{Cleanup:}
Die Cleanup Methode wird einmal aufgerufen, nachdem Key/Value – Paare an die Map Methode übergeben wurden. Auch hier macht die Standardimplementierung nichts.

\paragraph{Run:}
Die Run Methode steuert den allgemeinen Ablauf innerhalb der JVM. Die Standardimplementierung ruft die Setup-Methode einmal auf, bevor sie wiederholt die Map- Methode für jedes Key/Value – Paar aufruft und anschließend die Cleanup Methode aufruft.

\section{Nr 3}
Siehe jar-File und die Dateien in src.
\end{document}
